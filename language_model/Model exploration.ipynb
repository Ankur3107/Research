{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 100)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(1000,100).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_type = tf.float32\n",
    "\n",
    "embedding_table = tf.convert_to_tensor(np.random.rand(1000,100), dtype=float_type)\n",
    "num_next_sentence_label = 2\n",
    "initializer = tf.keras.initializers.TruncatedNormal(\n",
    "      stddev=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_dense = tf.keras.layers.Dense(\n",
    "        100,\n",
    "        activation='sigmoid',\n",
    "        kernel_initializer=initializer)\n",
    "lm_layer_norm = tf.keras.layers.LayerNormalization(\n",
    "        axis=-1, epsilon=1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_lm_input_tensor = np.random.rand(128,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm_output = lm_dense(mask_lm_input_tensor)\n",
    "lm_output = lm_layer_norm(lm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([128, 100])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([128, 1000])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_output = tf.matmul(lm_output, embedding_table, transpose_b=True)\n",
    "lm_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([128, 1000])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_output = tf.nn.log_softmax(lm_output, axis=-1)\n",
    "lm_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x144294250>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.Dense(10, name='dense')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, config):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = config.embed_dim\n",
    "        self.num_heads = config.num_heads\n",
    "        if self.embed_dim % self.num_heads != 0:\n",
    "            raise ValueError(\n",
    "                f\"embedding dimension = {self.embed_dim} should be divisible by number of heads = {self.num_heads}\"\n",
    "            )\n",
    "        self.projection_dim = self.embed_dim // self.num_heads\n",
    "        self.query_dense = tf.keras.layers.Dense(self.embed_dim, name='query')\n",
    "        self.key_dense = tf.keras.layers.Dense(self.embed_dim, name='key')\n",
    "        self.value_dense = tf.keras.layers.Dense(self.embed_dim, name='value')\n",
    "        self.combine_heads = tf.keras.layers.Dense(self.embed_dim, name='combine')\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        query = self.separate_heads(\n",
    "            query, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        key = self.separate_heads(\n",
    "            key, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        value = self.separate_heads(\n",
    "            value, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "        attention = tf.transpose(\n",
    "            attention, perm=[0, 2, 1, 3]\n",
    "        )  # (batch_size, seq_len, num_heads, projection_dim)\n",
    "        concat_attention = tf.reshape(\n",
    "            attention, (batch_size, -1, self.embed_dim)\n",
    "        )  # (batch_size, seq_len, embed_dim)\n",
    "        output = self.combine_heads(\n",
    "            concat_attention\n",
    "        )  # (batch_size, seq_len, embed_dim)\n",
    "        return output\n",
    "\n",
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, config):#embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadSelfAttention(config)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [tf.keras.layers.Dense(config.ff_dim, activation=\"relu\"), tf.keras.layers.Dense(config.embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(config.rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(config.rate)\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        attn_output = self.att(inputs)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "class TokenAndPositionEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, config, embedding_matrix, is_embedding_trainable, is_position_embedding_trainable):#maxlen, vocab_size, emded_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = tf.keras.layers.Embedding(input_dim=config.vocab_size, output_dim=config.embed_dim, trainable=is_embedding_trainable, weights=[embedding_matrix], name='word_embedding')\n",
    "        self.pos_emb = tf.keras.layers.Embedding(input_dim=config.maxlen, output_dim=config.embed_dim, trainable=is_position_embedding_trainable, weights=[get_pos_encoding_matrix(config.maxlen, config.embed_dim)], name='position_embedding')\n",
    "\n",
    "    def __call__(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions\n",
    "\n",
    "def get_pos_encoding_matrix(max_len, d_emb):\n",
    "\tpos_enc = np.array([\n",
    "\t\t[pos / np.power(10000, 2 * (j // 2) / d_emb) for j in range(d_emb)] \n",
    "\t\tif pos != 0 else np.zeros(d_emb) \n",
    "\t\t\tfor pos in range(max_len)\n",
    "\t\t\t])\n",
    "\tpos_enc[1:, 0::2] = np.sin(pos_enc[1:, 0::2]) # dim 2i\n",
    "\tpos_enc[1:, 1::2] = np.cos(pos_enc[1:, 1::2]) # dim 2i+1\n",
    "\treturn pos_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaTransformer():\n",
    "    def __init__(self, config, embedding_matrix=None, is_embedding_trainable=False, is_position_embedding_trainable=False):\n",
    "        if embedding_matrix is None:\n",
    "            embedding_matrix = np.zeros((config.vocab_size, config.embed_dim))\n",
    "\n",
    "        self.config = config\n",
    "        self.embedding_matrix = embedding_matrix\n",
    "        self.is_embedding_trainable = is_embedding_trainable\n",
    "        self.is_position_embedding_trainable = is_position_embedding_trainable\n",
    "\n",
    "        self.pooler_transform = tf.keras.layers.Dense(\n",
    "                                units=self.config.embed_dim,\n",
    "                                activation=\"tanh\",\n",
    "                                name=\"pooler_transform\")\n",
    "\n",
    "    def __call__(self, pre_layer):\n",
    "        embedding_layer = TokenAndPositionEmbedding(self.config, self.embedding_matrix, self.is_embedding_trainable, self.is_position_embedding_trainable)(pre_layer)\n",
    "        sequence_output = TransformerBlock(self.config)(embedding_layer)\n",
    "        first_token_tensor = tf.squeeze(sequence_output[:, 0:1, :], axis=1)\n",
    "        pooled_output = self.pooler_transform(first_token_tensor)\n",
    "        return (pooled_output,sequence_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape (TensorFlowOp [(2,)]               0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [()]                 0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_range (TensorFlowOp [(None,)]            0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "word_embedding (Embedding)      (None, 128, 512)     512000      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "position_embedding (Embedding)  (None, 512)          65536       tf_op_layer_range[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add (TensorFlowOpLa [(None, 128, 512)]   0           word_embedding[0][0]             \n",
      "                                                                 position_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_1 (TensorFlow [(3,)]               0           tf_op_layer_add[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [()]                 0           tf_op_layer_Shape_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "key (Dense)                     (None, 128, 512)     262656      tf_op_layer_add[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1/shape (Te [(4,)]               0           tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1 (TensorFl [(None, None, 8, 64) 0           key[0][0]                        \n",
      "                                                                 tf_op_layer_Reshape_1/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_transpose_1 (Tensor [(None, 8, None, 64) 0           tf_op_layer_Reshape_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "query (Dense)                   (None, 128, 512)     262656      tf_op_layer_add[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape/shape (Tens [(4,)]               0           tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_2 (TensorFlow [(4,)]               0           tf_op_layer_transpose_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, None, 8, 64) 0           query[0][0]                      \n",
      "                                                                 tf_op_layer_Reshape/shape[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [()]                 0           tf_op_layer_Shape_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_transpose (TensorFl [(None, 8, None, 64) 0           tf_op_layer_Reshape[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Cast (TensorFlowOpL [()]                 0           tf_op_layer_strided_slice_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_MatMul (TensorFlowO [(None, 8, None, Non 0           tf_op_layer_transpose[0][0]      \n",
      "                                                                 tf_op_layer_transpose_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sqrt (TensorFlowOpL [()]                 0           tf_op_layer_Cast[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "value (Dense)                   (None, 128, 512)     262656      tf_op_layer_add[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2/shape (Te [(4,)]               0           tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_truediv (TensorFlow [(None, 8, None, Non 0           tf_op_layer_MatMul[0][0]         \n",
      "                                                                 tf_op_layer_Sqrt[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2 (TensorFl [(None, None, 8, 64) 0           value[0][0]                      \n",
      "                                                                 tf_op_layer_Reshape_2/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softmax (TensorFlow [(None, 8, None, Non 0           tf_op_layer_truediv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_transpose_2 (Tensor [(None, 8, None, 64) 0           tf_op_layer_Reshape_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_MatMul_1 (TensorFlo [(None, 8, None, 64) 0           tf_op_layer_Softmax[0][0]        \n",
      "                                                                 tf_op_layer_transpose_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_transpose_3 (Tensor [(None, None, 8, 64) 0           tf_op_layer_MatMul_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3/shape (Te [(3,)]               0           tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3 (TensorFl [(None, None, 512)]  0           tf_op_layer_transpose_3[0][0]    \n",
      "                                                                 tf_op_layer_Reshape_3/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "combine (Dense)                 (None, None, 512)    262656      tf_op_layer_Reshape_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, None, 512)    0           combine[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_1 (TensorFlowOp [(None, 128, 512)]   0           tf_op_layer_add[0][0]            \n",
      "                                                                 dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 128, 512)     1024        tf_op_layer_add_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 128, 512)     33312       layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128, 512)     0           sequential[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_2 (TensorFlowOp [(None, 128, 512)]   0           layer_normalization[0][0]        \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 128, 512)     1024        tf_op_layer_add_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [(None, 1, 512)]     0           layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze (TensorFlow [(None, 512)]        0           tf_op_layer_strided_slice_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "pooler_transform (Dense)        (None, 512)          262656      tf_op_layer_Squeeze[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3)            1539        pooler_transform[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 1,927,715\n",
      "Trainable params: 1,350,179\n",
      "Non-trainable params: 577,536\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "config = argparse.Namespace(vocab_size=1000,\n",
    "                            embed_dim=512,\n",
    "                            ff_dim=32,\n",
    "                            num_heads=8,\n",
    "                            rate=0.1,\n",
    "                            maxlen=128)\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(config.maxlen,))\n",
    "pooled_output,sequence_output = VanillaTransformer(config)(inputs)\n",
    "output = tf.keras.layers.Dense(3, activation='softmax')(pooled_output)\n",
    "full_model = tf.keras.models.Model(inputs=inputs, outputs=output)\n",
    "print(full_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to create group (name already exists)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-48896b269e42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfull_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'transformer.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/tf2_env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m    973\u001b[0m     \"\"\"\n\u001b[1;32m    974\u001b[0m     saving.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m--> 975\u001b[0;31m                       signatures, options)\n\u001b[0m\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2_env/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m    110\u001b[0m           'or using `save_weights`.')\n\u001b[1;32m    111\u001b[0m     hdf5_format.save_model_to_hdf5(\n\u001b[0;32m--> 112\u001b[0;31m         model, filepath, overwrite, include_optimizer)\n\u001b[0m\u001b[1;32m    113\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n",
      "\u001b[0;32m~/tf2_env/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mmodel_weights_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mmodel_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0msave_weights_to_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_weights_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;31m# TODO(b/128683857): Add integration tests between tf.keras and external\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2_env/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36msave_weights_to_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_legacy_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0mweight_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2_env/lib/python3.7/site-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36mcreate_group\u001b[0;34m(self, name, track_order)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlcpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mgcpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcpl_crt_order\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrack_order\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mgid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5g\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mGroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5g.pyx\u001b[0m in \u001b[0;36mh5py.h5g.create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to create group (name already exists)"
     ]
    }
   ],
   "source": [
    "full_model.save('transformer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('tf2_env': venv)",
   "language": "python",
   "name": "python37564bittf2envvenv9baad5f63bf544adb456767f347f0830"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
