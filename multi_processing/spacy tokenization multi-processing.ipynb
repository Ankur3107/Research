{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from fastprogress import *\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import re\n",
    "\n",
    "def parallel(func, arr, max_workers=4):\n",
    "    if max_workers<2: results = list(progress_bar(map(func, enumerate(arr)), total=len(arr)))\n",
    "    else:\n",
    "        with ProcessPoolExecutor(max_workers=max_workers) as ex:\n",
    "            return list(progress_bar(ex.map(func, enumerate(arr)), total=len(arr)))\n",
    "    if any([o is not None for o in results]): return results\n",
    "    \n",
    "def listify(o):\n",
    "    if o is None: return []\n",
    "    if isinstance(o, list): return o\n",
    "    if isinstance(o, str): return [o]\n",
    "    if isinstance(o, Iterable): return list(o)\n",
    "    return [o]\n",
    "\n",
    "def compose(x, funcs, *args, order_key='_order', **kwargs):\n",
    "    key = lambda o: getattr(o, order_key, 0)\n",
    "    for f in sorted(listify(funcs), key=key): x = f(x, **kwargs)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenizeProcessor():\n",
    "    def __init__(self, nlp, chunksize=2000, pre_rules=None, post_rules=None, max_workers=4): \n",
    "        self.chunksize,self.max_workers = chunksize,max_workers\n",
    "        self.tokenizer = nlp.tokenizer\n",
    "        self.pre_rules  = pre_rules \n",
    "        self.post_rules = post_rules\n",
    "\n",
    "    def proc_chunk(self, args):\n",
    "        i,chunk = args\n",
    "        chunk = [compose(t, self.pre_rules) for t in chunk]\n",
    "        docs = [[d.text for d in doc] for doc in self.tokenizer.pipe(chunk)]\n",
    "        docs = [compose(t, self.post_rules) for t in docs]\n",
    "        return docs\n",
    "\n",
    "    def __call__(self, items): \n",
    "        toks = []\n",
    "        chunks = [items[i: i+self.chunksize] for i in (range(0, len(items), self.chunksize))]\n",
    "        toks = parallel(self.proc_chunk, chunks, max_workers=self.max_workers)\n",
    "        return sum(toks, [])\n",
    "    \n",
    "    def proc1(self, item): return self.proc_chunk([item])[0]\n",
    "    \n",
    "    def deprocess(self, toks): return [self.deproc1(tok) for tok in toks]\n",
    "    def deproc1(self, tok):    return \" \".join(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_thread_based_tokenizations(nlp, text_list, n_threads=4):\n",
    "    docs = nlp.pipe(text_list, n_threads = n_threads)\n",
    "    word_sequences = []\n",
    "    \n",
    "    for doc in tqdm(docs):\n",
    "        word_seq = []\n",
    "        for token in doc:\n",
    "            word_seq.append(token.text)\n",
    "        word_sequences.append(word_seq)\n",
    "    return word_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"This is a text\", \"These are lots of texts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = TokenizeProcessor(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:01<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[['This', 'is', 'a', 'text'], ['These', 'are', 'lots', 'of', 'texts']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 101.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['This', 'is', 'a', 'text'], ['These', 'are', 'lots', 'of', 'texts']]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_sequences = multi_thread_based_tokenizations(nlp, texts)\n",
    "word_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/ankur.kumar/Desktop/Work/projects/client/pantaloon/Pantaloon-MH-processed.csv')[['UID', 'Cleaned_Verbatim']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(['UID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[0:10000]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cleaned_Verbatim'] = df['Cleaned_Verbatim'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Verbatims = df.Cleaned_Verbatim.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with multi threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "1it [00:04,  4.39s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "1001it [00:08,  3.07s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "2001it [00:13,  2.15s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "3001it [00:17,  1.51s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "4001it [00:22,  1.06s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "5001it [00:27,  1.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "6001it [00:31,  1.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "7001it [00:35,  2.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "8001it [00:39,  3.89it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "10000it [00:43, 227.69it/s]A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.9 s, sys: 7 s, total: 43.9 s\n",
      "Wall time: 43.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "word_sequences = multi_thread_based_tokenizations(nlp, Verbatims, 4)\n",
    "len(word_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with multi processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [5/5 00:05<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.93 s, sys: 600 ms, total: 4.53 s\n",
      "Wall time: 5.47 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tp = TokenizeProcessor(nlp, chunksize=2000, max_workers=4)\n",
    "word_sequences = tp(Verbatims)\n",
    "len(word_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1',\n",
       "  '.',\n",
       "  'the',\n",
       "  'fit',\n",
       "  '&',\n",
       "  'price',\n",
       "  'was',\n",
       "  'good',\n",
       "  '.',\n",
       "  '2',\n",
       "  '.',\n",
       "  'i',\n",
       "  'was',\n",
       "  'not',\n",
       "  'looking',\n",
       "  'for',\n",
       "  'any',\n",
       "  'particular',\n",
       "  'brand',\n",
       "  'or',\n",
       "  'product',\n",
       "  '.',\n",
       "  '3',\n",
       "  '.',\n",
       "  'this',\n",
       "  'is',\n",
       "  'was',\n",
       "  'just',\n",
       "  'a',\n",
       "  'casual',\n",
       "  'shopping',\n",
       "  '.',\n",
       "  '4',\n",
       "  '.',\n",
       "  'the',\n",
       "  'staff',\n",
       "  'did',\n",
       "  'assist',\n",
       "  'me',\n",
       "  'well',\n",
       "  '.',\n",
       "  '5',\n",
       "  '.',\n",
       "  'apart',\n",
       "  'form',\n",
       "  'pantaloons',\n",
       "  'i',\n",
       "  'also',\n",
       "  'shop',\n",
       "  'west',\n",
       "  '-',\n",
       "  'side6',\n",
       "  '.',\n",
       "  'recommend',\n",
       "  'pantaloons',\n",
       "  'to',\n",
       "  'friends',\n",
       "  '&',\n",
       "  'family',\n",
       "  '-',\n",
       "  'yes'],\n",
       " ['1',\n",
       "  '.',\n",
       "  'i',\n",
       "  'am',\n",
       "  'satisfied',\n",
       "  'with',\n",
       "  'the',\n",
       "  'staff',\n",
       "  'service',\n",
       "  '.',\n",
       "  '2',\n",
       "  '.',\n",
       "  'the',\n",
       "  'staff',\n",
       "  'was',\n",
       "  'very',\n",
       "  'helpful',\n",
       "  'to',\n",
       "  'me',\n",
       "  '.',\n",
       "  '3',\n",
       "  '.',\n",
       "  'they',\n",
       "  'explained',\n",
       "  'me',\n",
       "  'about',\n",
       "  'the',\n",
       "  'products',\n",
       "  '.',\n",
       "  '4',\n",
       "  '.',\n",
       "  'recommend',\n",
       "  'pantaloons',\n",
       "  'to',\n",
       "  'friends',\n",
       "  '&',\n",
       "  'family',\n",
       "  '-',\n",
       "  'yes'],\n",
       " ['1',\n",
       "  '.',\n",
       "  'i',\n",
       "  'am',\n",
       "  'fine',\n",
       "  'with',\n",
       "  'the',\n",
       "  'range',\n",
       "  'and',\n",
       "  'variety',\n",
       "  '.',\n",
       "  '2',\n",
       "  '.',\n",
       "  'the',\n",
       "  'fit',\n",
       "  'and',\n",
       "  'price',\n",
       "  'is',\n",
       "  'also',\n",
       "  'good',\n",
       "  '.',\n",
       "  '3',\n",
       "  '.',\n",
       "  'i',\n",
       "  'got',\n",
       "  'all',\n",
       "  'the',\n",
       "  'products',\n",
       "  'whatever',\n",
       "  'i',\n",
       "  'was',\n",
       "  'looking',\n",
       "  '.',\n",
       "  '4',\n",
       "  '.',\n",
       "  'it',\n",
       "  'was',\n",
       "  'a',\n",
       "  'casual',\n",
       "  'shopping',\n",
       "  '5',\n",
       "  '.',\n",
       "  'staff',\n",
       "  'was',\n",
       "  'also',\n",
       "  'good',\n",
       "  'they',\n",
       "  'helped',\n",
       "  'me',\n",
       "  '6',\n",
       "  '.',\n",
       "  'recommend',\n",
       "  'pantaloons',\n",
       "  'with',\n",
       "  'friends',\n",
       "  'and',\n",
       "  'family',\n",
       "  '-',\n",
       "  'yes'],\n",
       " ['1',\n",
       "  '.',\n",
       "  'i',\n",
       "  'like',\n",
       "  'the',\n",
       "  'the',\n",
       "  'product',\n",
       "  'quality',\n",
       "  '2',\n",
       "  '.',\n",
       "  'i',\n",
       "  'like',\n",
       "  'material',\n",
       "  'quality',\n",
       "  'of',\n",
       "  'the',\n",
       "  'product3',\n",
       "  '.',\n",
       "  'i',\n",
       "  'like',\n",
       "  'the',\n",
       "  'fabric',\n",
       "  'quality',\n",
       "  'product4',\n",
       "  '.',\n",
       "  'i',\n",
       "  'like',\n",
       "  'the',\n",
       "  'color',\n",
       "  'of',\n",
       "  'the',\n",
       "  'product5',\n",
       "  '.',\n",
       "  'i',\n",
       "  'like',\n",
       "  'the',\n",
       "  'product',\n",
       "  'finish',\n",
       "  '6',\n",
       "  '.',\n",
       "  'recommend',\n",
       "  'pantaloons',\n",
       "  'with',\n",
       "  'friends',\n",
       "  'and',\n",
       "  'family',\n",
       "  '-',\n",
       "  'yes'],\n",
       " ['1',\n",
       "  '.',\n",
       "  'staff',\n",
       "  'service',\n",
       "  'is',\n",
       "  'good',\n",
       "  'and',\n",
       "  'i',\n",
       "  'am',\n",
       "  'satisfied',\n",
       "  '.',\n",
       "  '2',\n",
       "  '.',\n",
       "  'staff',\n",
       "  'understood',\n",
       "  'my',\n",
       "  'requirement',\n",
       "  'and',\n",
       "  'showed',\n",
       "  'the',\n",
       "  'right',\n",
       "  'product',\n",
       "  '.',\n",
       "  '3',\n",
       "  '.',\n",
       "  'recommend',\n",
       "  'pantaloons',\n",
       "  'to',\n",
       "  'my',\n",
       "  'family',\n",
       "  'and',\n",
       "  'friends',\n",
       "  '-',\n",
       "  'yes'],\n",
       " ['1',\n",
       "  '.',\n",
       "  'the',\n",
       "  'cashier',\n",
       "  'behavior',\n",
       "  'was',\n",
       "  'good',\n",
       "  'at',\n",
       "  'the',\n",
       "  'store',\n",
       "  '.',\n",
       "  '2',\n",
       "  '.',\n",
       "  'recommend',\n",
       "  'pantaloons',\n",
       "  'to',\n",
       "  'friends',\n",
       "  'and',\n",
       "  'family',\n",
       "  '-',\n",
       "  'yes',\n",
       "  '.'],\n",
       " ['1',\n",
       "  '.',\n",
       "  'the',\n",
       "  'billing',\n",
       "  'service',\n",
       "  'was',\n",
       "  'good',\n",
       "  '.',\n",
       "  '2',\n",
       "  '.',\n",
       "  'cashier',\n",
       "  'behaviour',\n",
       "  'was',\n",
       "  'also',\n",
       "  'fine',\n",
       "  '.',\n",
       "  '3',\n",
       "  '.',\n",
       "  'my',\n",
       "  'billing',\n",
       "  'was',\n",
       "  'also',\n",
       "  'done',\n",
       "  'quickly',\n",
       "  '.',\n",
       "  '4',\n",
       "  '.',\n",
       "  'recommend',\n",
       "  'pantaloons',\n",
       "  'with',\n",
       "  'friends',\n",
       "  'and',\n",
       "  'family',\n",
       "  '-',\n",
       "  'yes'],\n",
       " ['1',\n",
       "  '.',\n",
       "  'i',\n",
       "  'was',\n",
       "  'looking',\n",
       "  'for',\n",
       "  'shorts',\n",
       "  'in',\n",
       "  'men',\n",
       "  'section',\n",
       "  '2',\n",
       "  '.',\n",
       "  'i',\n",
       "  'was',\n",
       "  'looking',\n",
       "  'for',\n",
       "  'xl',\n",
       "  'size',\n",
       "  'for',\n",
       "  'casual',\n",
       "  'wear',\n",
       "  '3',\n",
       "  '.',\n",
       "  'i',\n",
       "  'shop',\n",
       "  'from',\n",
       "  'reliance',\n",
       "  'trends',\n",
       "  'apart',\n",
       "  'from',\n",
       "  'pantaloons'],\n",
       " ['1',\n",
       "  '.',\n",
       "  'i',\n",
       "  'like',\n",
       "  'the',\n",
       "  'material',\n",
       "  'quality',\n",
       "  'of',\n",
       "  'the',\n",
       "  'product',\n",
       "  '.',\n",
       "  '2',\n",
       "  '.',\n",
       "  'recommend',\n",
       "  'to',\n",
       "  'friends',\n",
       "  'and',\n",
       "  'family',\n",
       "  '-',\n",
       "  'yes'],\n",
       " ['1',\n",
       "  'i',\n",
       "  'was',\n",
       "  'very',\n",
       "  'happy',\n",
       "  'with',\n",
       "  'the',\n",
       "  'staff',\n",
       "  'service',\n",
       "  'at',\n",
       "  'pantaloons2',\n",
       "  'staff',\n",
       "  'behavior',\n",
       "  'was',\n",
       "  'good',\n",
       "  'and',\n",
       "  'they',\n",
       "  'were',\n",
       "  'able',\n",
       "  'help',\n",
       "  'me',\n",
       "  'in',\n",
       "  'finding',\n",
       "  'the',\n",
       "  'products',\n",
       "  'in',\n",
       "  'women',\n",
       "  's',\n",
       "  'western',\n",
       "  'wear',\n",
       "  '3',\n",
       "  'recommend',\n",
       "  'pantaloons',\n",
       "  'to',\n",
       "  'friends',\n",
       "  'and',\n",
       "  'family',\n",
       "  '-',\n",
       "  'yes']]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_sequences[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('tf2_env': venv)",
   "language": "python",
   "name": "python37564bittf2envvenv9baad5f63bf544adb456767f347f0830"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
