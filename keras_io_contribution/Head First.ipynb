{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(keras.layers.Layer):\n",
    "    r\"\"\"The attention layer that takes three inputs representing queries, keys and values.\n",
    "    \\text{Attention}(Q, K, V) = \\text{softmax}(\\frac{Q K^T}{\\sqrt{d_k}}) V\n",
    "    See: https://arxiv.org/pdf/1706.03762.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 return_attention=False,\n",
    "                 **kwargs):\n",
    "        \"\"\"Initialize the layer.\n",
    "        :param return_attention: Whether to return attention weights.\n",
    "        :param kwargs: Arguments for parent class.\n",
    "        \"\"\"\n",
    "        super(ScaledDotProductAttention, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.return_attention = return_attention\n",
    "        \n",
    "\n",
    "    def call(self, inputs, mask=None, **kwargs):\n",
    "        if isinstance(inputs, list):\n",
    "            query, key, value = inputs\n",
    "        else:\n",
    "            query = key = value = inputs\n",
    "        if isinstance(mask, list):\n",
    "            mask = mask[1]\n",
    "\n",
    "        feature_dim = K.shape(query)[-1]\n",
    "        e = K.batch_dot(query, key, axes=2) / K.sqrt(K.cast(feature_dim, dtype=K.floatx()))\n",
    "        e = K.exp(e - K.max(e, axis=-1, keepdims=True))\n",
    "        \n",
    "        if mask is not None:\n",
    "            e *= K.cast(K.expand_dims(mask, axis=-2), K.floatx())\n",
    "            \n",
    "        a = e / (K.sum(e, axis=-1, keepdims=True) + K.epsilon())\n",
    "        v = K.batch_dot(a, value)\n",
    "        \n",
    "        if self.return_attention:\n",
    "            return [v, a]\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (100,)\n",
    "model_input = Input(shape=input_shape)\n",
    "embedding_layer = Embedding(1000, 128)(model_input)\n",
    "embedding_dropout_layer = SpatialDropout1D(0.3)(embedding_layer)\n",
    "bilstm_layer = Bidirectional(LSTM(256, return_sequences=True))(embedding_dropout_layer)\n",
    "scaled_attention_layer = ScaledDotProductAttention()(bilstm_layer)\n",
    "max_pool_layer = GlobalMaxPooling1D()(scaled_attention_layer)\n",
    "output = Dense(3, activation='softmax')(max_pool_layer)\n",
    "full_model = Model(inputs=model_input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 100, 128)          128000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_2 (Spatial (None, 100, 128)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 100, 512)          788480    \n",
      "_________________________________________________________________\n",
      "scaled_dot_product_attention (None, 100, 512)          0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 918,019\n",
      "Trainable params: 918,019\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('tf2_env': venv)",
   "language": "python",
   "name": "python37564bittf2envvenv9baad5f63bf544adb456767f347f0830"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
